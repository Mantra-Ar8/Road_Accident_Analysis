{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0f9212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (37, 63)\n",
      "Columns: ['Sl. No', 'States/UTs', 'Fault of Driver-Total No. of Road Accidents - 2014', 'Fault of Driver-Total No. of Road Accidents - 2014 per 1L people', 'Fault of Driver-Number of Persons-Killed - 2014', 'Fault of Driver-Number of Persons-Killed - 2014 per 1L people', 'Fault of Driver-Number of Persons-Injured - 2014', 'Fault of Driver-Number of Persons-Injured - 2014 per 1L people', 'Fault of Driver of other vehicles-Total No. of Road Accidents - 2014', 'Fault of Driver of other vehicles-Total No. of Road Accidents - 2014 per 1L people', 'Fault of Driver of other vehicles-Number of Persons-Killed - 2014', 'Fault of Driver of other vehicles-Number of Persons-Killed - 2014 per 1L people', 'Fault of Driver of other vehicles-Number of Persons-Injured - 2014', 'Fault of Driver of other vehicles-Number of Persons-Injured - 2014 per 1L people', 'Fault of Pedestrian-Total No. of Road Accidents - 2014', 'Fault of Pedestrian-Total No. of Road Accidents - 2014 per 1L people', 'Fault of Pedestrian-Number of Persons-Killed - 2014', 'Fault of Pedestrian-Number of Persons-Killed - 2014 per 1L people', 'Fault of Pedestrian-Number of Persons-Injured - 2014', 'Fault of Pedestrian-Number of Persons-Injured - 2014 per 1L people', 'Defect in Condition of Motor Vehicle-Total No. of Road Accidents - 2014', 'Defect in Condition of Motor Vehicle-Total No. of Road Accidents - 2014 per 1L people', 'Defect in Condition of Motor Vehicle-Number of Persons-Killed - 2014', 'Defect in Condition of Motor Vehicle-Number of Persons-Killed - 2014 per 1L people', 'Defect in Condition of Motor Vehicle-Number of Persons-Injured - 2014', 'Defect in Condition of Motor Vehicle-Number of Persons-Injured - 2014 per 1L people', 'Defect in Road Condition-Total No. of Road Accidents - 2014', 'Defect in Road Condition-Total No. of Road Accidents - 2014 per 1L people', 'Defect in Road Condition-Number of Persons-Killed - 2014', 'Defect in Road Condition-Number of Persons-Killed - 2014 per 1L people', 'Defect in Road Condition-Number of Persons-Injured - 2014', 'Defect in Road Condition-Number of Persons-Injured - 2014 per 1L people', 'Weather Condition-Total No. of Road Accidents - 2014', 'Weather Condition-Total No. of Road Accidents - 2014 per 1L people', 'Weather Condition-Number of Persons-Killed - 2014', 'Weather Condition-Number of Persons-Killed - 2014 per 1L people', 'Weather Condition-Number of Persons-Injured - 2014', 'Weather Condition-Number of Persons-Injured - 2014 per 1L people', 'Fault of Passenger-Total No. of Road Accidents - 2014', 'Fault of Passenger-Total No. of Road Accidents - 2014 per 1L people', 'Fault of Passenger-Number of Persons-Killed - 2014', 'Fault of Passenger-Number of Persons-Killed - 2014 per 1L people', 'Fault of Passenger-Number of Persons-Injured - 2014', 'Fault of Passenger-Number of Persons-Injured - 2014 per 1L people', 'Poor light-Total No. of Road Accidents - 2014', 'Poor light-Total No. of Road Accidents - 2014 per 1L people', 'Poor light-Number of Persons-Killed - 2014', 'Poor light-Number of Persons-Killed - 2014 per 1L people', 'Poor light-Number of Persons-Injured - 2014', 'Poor light-Number of Persons-Injured - 2014 per 1L people', 'Falling of boulders-Total No. of Road Accidents - 2014', 'Falling of boulders-Total No. of Road Accidents - 2014 per 1L people', 'Falling of boulders-Number of Persons-Killed - 2014', 'Falling of boulders-Number of Persons-Killed - 2014 per 1L people', 'Falling of boulders-Number of Persons-Injured - 2014', 'Falling of boulders-Number of Persons-Injured - 2014 per 1L people', 'Other causes/causes not known-Total No. of Road Accidents - 2014', 'Other causes/causes not known-Total No. of Road Accidents - 2014 per 1L people', 'Other causes/causes not known-Number of Persons-Killed - 2014', 'Other causes/causes not known-Number of Persons-Killed - 2014 per 1L people', 'Other causes/causes not known-Number of Persons-Injured - 2014', 'Other causes/causes not known-Number of Persons-Injured - 2014 per 1L people', 'Population']\n",
      "Selected reason column → Fault of Driver-Total No. of Road Accidents - 2014\n",
      "\n",
      "Category distribution:\n",
      "reason_category\n",
      "Driver Fault      33\n",
      "Vehicle Defect     2\n",
      "Poor Light         1\n",
      "Other              1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "====================== MODEL ACCURACY ======================\n",
      "Logistic Regression: 1.0\n",
      "Random Forest: 1.0\n",
      "XGBoost: 1.0\n",
      "\n",
      "Best Model: Logistic Regression\n",
      "\n",
      "Saved:\n",
      "- accident_reason_model.pkl\n",
      "- scaler.pkl\n",
      "- label_encoder.pkl\n",
      "- imputer.pkl\n",
      "\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\KIIT\\Desktop\\1\\RoadAccidentsInIndia\\ModifiedDatabase\\reasonOfAccident.csv\", on_bad_lines=\"skip\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "\n",
    "def find_reason_column(df):\n",
    "    keywords = [\"reason\", \"cause\", \"fault\", \"accident\"]\n",
    "    for col in df.columns:\n",
    "        if any(k in col.lower() for k in keywords):\n",
    "            return col\n",
    "\n",
    "    # fallback → largest object/text column\n",
    "    obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "    if obj_cols:\n",
    "        return obj_cols[0]\n",
    "\n",
    "    return df.columns[0]\n",
    "\n",
    "\n",
    "reason_col = find_reason_column(df)\n",
    "print(\"Selected reason column →\", reason_col)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Clean reason text\n",
    "# ------------------------------------------------------------\n",
    "def clean_text(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"[^\\w\\s\\-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "df[\"reason_clean\"] = df[reason_col].astype(str).map(clean_text)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Create reason categories (target variable)\n",
    "# ------------------------------------------------------------\n",
    "# Since this dataset contains statistics by state/fault type,\n",
    "# create categories based on the fault type columns present\n",
    "def create_categories_from_columns(df):\n",
    "    # Extract main fault types from column names\n",
    "    fault_types = set()\n",
    "    for col in df.columns:\n",
    "        if \"Fault of Driver-Total\" in col:\n",
    "            fault_types.add(\"Driver Fault\")\n",
    "        elif \"Fault of Driver of other\" in col:\n",
    "            fault_types.add(\"Other Driver Fault\")\n",
    "        elif \"Fault of Pedestrian\" in col:\n",
    "            fault_types.add(\"Pedestrian Fault\")\n",
    "        elif \"Defect in Condition of Motor Vehicle\" in col:\n",
    "            fault_types.add(\"Vehicle Defect\")\n",
    "        elif \"Defect in Road Condition\" in col:\n",
    "            fault_types.add(\"Road Defect\")\n",
    "        elif \"Weather Condition\" in col:\n",
    "            fault_types.add(\"Weather\")\n",
    "        elif \"Fault of Passenger\" in col:\n",
    "            fault_types.add(\"Passenger Fault\")\n",
    "        elif \"Poor light\" in col:\n",
    "            fault_types.add(\"Poor Light\")\n",
    "    \n",
    "    # Assign category based on dominant accident count\n",
    "    categories = []\n",
    "    for idx, row in df.iterrows():\n",
    "        max_accidents = -1\n",
    "        dominant_category = \"Other\"\n",
    "        \n",
    "        checks = [\n",
    "            (\"Driver Fault\", \"Fault of Driver-Total No. of Road Accidents - 2014\"),\n",
    "            (\"Other Driver Fault\", \"Fault of Driver of other vehicles-Total No. of Road Accidents - 2014\"),\n",
    "            (\"Pedestrian Fault\", \"Fault of Pedestrian-Total No. of Road Accidents - 2014\"),\n",
    "            (\"Vehicle Defect\", \"Defect in Condition of Motor Vehicle-Total No. of Road Accidents - 2014\"),\n",
    "            (\"Road Defect\", \"Defect in Road Condition-Total No. of Road Accidents - 2014\"),\n",
    "            (\"Weather\", \"Weather Condition-Total No. of Road Accidents - 2014\"),\n",
    "            (\"Passenger Fault\", \"Fault of Passenger-Total No. of Road Accidents - 2014\"),\n",
    "            (\"Poor Light\", \"Poor light-Total No. of Road Accidents - 2014\"),\n",
    "        ]\n",
    "        \n",
    "        for cat_name, col_name in checks:\n",
    "            if col_name in df.columns:\n",
    "                val = row[col_name]\n",
    "                if pd.notna(val) and val > max_accidents:\n",
    "                    max_accidents = val\n",
    "                    dominant_category = cat_name\n",
    "        \n",
    "        categories.append(dominant_category)\n",
    "    \n",
    "    return categories\n",
    "\n",
    "df[\"reason_category\"] = create_categories_from_columns(df)\n",
    "\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(df[\"reason_category\"].value_counts())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Select features (X) and target (y) for ML\n",
    "# ------------------------------------------------------------\n",
    "# Use all numeric columns as features\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "if len(numeric_cols) == 0:\n",
    "    raise Exception(\"No numeric columns available for ML model!\")\n",
    "\n",
    "X = df[numeric_cols]\n",
    "y = df[\"reason_category\"]\n",
    "\n",
    "# if target has missing values drop them (very few / none in this dataset)\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Encode target classes\n",
    "# ------------------------------------------------------------\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Train-test split\n",
    "# ------------------------------------------------------------\n",
    "# Check if stratification is possible (all classes must have at least 2 samples)\n",
    "class_counts = pd.Series(y_encoded).value_counts()\n",
    "stratify_option = y_encoded if (class_counts >= 2).all() else None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=stratify_option\n",
    ")\n",
    "\n",
    "\n",
    "# Impute missing numeric values (fit on train only)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scale numeric features (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9. Train multiple ML models\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# 1. Logistic Regression (requires scaling)\n",
    "log_reg = LogisticRegression(max_iter=2000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "pred_lr = log_reg.predict(X_test_scaled)\n",
    "acc_lr = accuracy_score(y_test, pred_lr)\n",
    "\n",
    "# 2. Random Forest (tree-based → scaling not required, use imputed data)\n",
    "rf = RandomForestClassifier(n_estimators=400, random_state=42)\n",
    "rf.fit(X_train_imputed, y_train)\n",
    "pred_rf = rf.predict(X_test_imputed)\n",
    "acc_rf = accuracy_score(y_test, pred_rf)\n",
    "\n",
    "# 3. XGBoost (tree-based → scaling not required, use imputed data)\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=250,\n",
    "    subsample=0.8,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "xgb.fit(X_train_imputed, y_train)\n",
    "pred_xgb = xgb.predict(X_test_imputed)\n",
    "acc_xgb = accuracy_score(y_test, pred_xgb)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10. Print performance\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n====================== MODEL ACCURACY ======================\")\n",
    "print(\"Logistic Regression:\", acc_lr)\n",
    "print(\"Random Forest:\", acc_rf)\n",
    "print(\"XGBoost:\", acc_xgb)\n",
    "\n",
    "best_model = None\n",
    "best_name = None\n",
    "best_acc = max(acc_lr, acc_rf, acc_xgb)\n",
    "\n",
    "if best_acc == acc_lr:\n",
    "    best_model = log_reg\n",
    "    best_name = \"Logistic Regression\"\n",
    "elif best_acc == acc_rf:\n",
    "    best_model = rf\n",
    "    best_name = \"Random Forest\"\n",
    "else:\n",
    "    best_model = xgb\n",
    "    best_name = \"XGBoost\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 11. Save trained model + scaler + label encoder + imputer\n",
    "# ------------------------------------------------------------\n",
    "joblib.dump(best_model, \"accident_reason_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(imputer, \"imputer.pkl\")\n",
    "\n",
    "print(\"\\nBest Model:\", best_name)\n",
    "print(\"\\nSaved:\")\n",
    "print(\"- accident_reason_model.pkl\")\n",
    "print(\"- scaler.pkl\")\n",
    "print(\"- label_encoder.pkl\")\n",
    "print(\"- imputer.pkl\")\n",
    "\n",
    "print(\"\\nTraining Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b803bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================== PREDICTIONS FOR ALL STATES ======================\n",
      "               States/UTs reason_category predicted_reason\n",
      "0          Andhra Pradesh    Driver Fault     Driver Fault\n",
      "1       Arunachal Pradesh      Poor Light       Poor Light\n",
      "2                   Assam    Driver Fault     Driver Fault\n",
      "3                   Bihar    Driver Fault     Driver Fault\n",
      "4            Chhattisgarh    Driver Fault     Driver Fault\n",
      "5                     Goa    Driver Fault     Driver Fault\n",
      "6                 Gujarat    Driver Fault     Driver Fault\n",
      "7                 Haryana    Driver Fault     Driver Fault\n",
      "8        Himachal Pradesh    Driver Fault     Driver Fault\n",
      "9         Jammu & Kashmir    Driver Fault     Driver Fault\n",
      "10              Jharkhand    Driver Fault     Driver Fault\n",
      "11              Karnataka    Driver Fault     Driver Fault\n",
      "12                 Kerala    Driver Fault     Driver Fault\n",
      "13         Madhya Pradesh    Driver Fault     Driver Fault\n",
      "14            Maharashtra    Driver Fault     Driver Fault\n",
      "15                Manipur  Vehicle Defect   Vehicle Defect\n",
      "16              Meghalaya  Vehicle Defect   Vehicle Defect\n",
      "17                Mizoram    Driver Fault     Driver Fault\n",
      "18               Nagaland    Driver Fault     Driver Fault\n",
      "19                 Odisha    Driver Fault     Driver Fault\n",
      "20                 Punjab    Driver Fault     Driver Fault\n",
      "21              Rajasthan    Driver Fault     Driver Fault\n",
      "22                 Sikkim    Driver Fault     Driver Fault\n",
      "23             Tamil Nadu    Driver Fault     Driver Fault\n",
      "24              Telangana    Driver Fault     Driver Fault\n",
      "25                Tripura    Driver Fault     Driver Fault\n",
      "26            Uttarakhand    Driver Fault     Driver Fault\n",
      "27          Uttar Pradesh    Driver Fault     Driver Fault\n",
      "28            West Bengal    Driver Fault     Driver Fault\n",
      "29  Andaman & Nicobar Is.    Driver Fault     Driver Fault\n",
      "30             Chandigarh    Driver Fault     Driver Fault\n",
      "31   Dadra & Nagar Haveli    Driver Fault     Driver Fault\n",
      "32            Daman & Diu    Driver Fault     Driver Fault\n",
      "33                 Delhi            Other            Other\n",
      "34            Lakshadweep    Driver Fault     Driver Fault\n",
      "35             Puducherry    Driver Fault     Driver Fault\n",
      "36                 Total     Driver Fault     Driver Fault\n",
      "\n",
      "Results saved to 'accident_predictions_by_state.csv'\n"
     ]
    }
   ],
   "source": [
    "# Predict accident reason categories for all states\n",
    "X_all_imputed = imputer.transform(X)\n",
    "X_all_scaled = scaler.transform(X_all_imputed)\n",
    "\n",
    "# Use the best model (Logistic Regression) to predict for all data\n",
    "predictions_encoded = best_model.predict(X_all_scaled)\n",
    "predictions_labels = label_encoder.inverse_transform(predictions_encoded)\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df['predicted_reason'] = predictions_labels\n",
    "\n",
    "# Display results\n",
    "print(\"\\n====================== PREDICTIONS FOR ALL STATES ======================\")\n",
    "print(df[['States/UTs', 'reason_category', 'predicted_reason']].to_string())\n",
    "\n",
    "# Save results to CSV\n",
    "df[['States/UTs', 'reason_category', 'predicted_reason']].to_csv('accident_predictions_by_state.csv', index=False)\n",
    "print(\"\\nResults saved to 'accident_predictions_by_state.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240fed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
